{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c85a8a",
   "metadata": {},
   "source": [
    "# LangChain + Ollama: Connecting AI Agents to External APIs (Google Search)\n",
    "\n",
    "This notebook demonstrates how to use a locally running Ollama model to interact with external APIs, such as Google Search, through prompt engineering. You'll learn how to set up the environment, send API-related prompts, and interpret the model's output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4e0f0",
   "metadata": {},
   "source": [
    "# Install Required Packages\n",
    "To use LangChain with Ollama, you need to install the following Python packages:\n",
    "- `ollama`: Python client for locally running Ollama models\n",
    "- `langchain_community`: Community-contributed LangChain tools\n",
    "- `python-dotenv`: For loading environment variables from a `.env` file\n",
    "- `requests`: For making API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8d8ecb",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "We need to import the following libraries:\n",
    "- `os`: For accessing environment variables\n",
    "- `load_dotenv` from `dotenv`: To load variables from a `.env` file\n",
    "- `ollama`: To interact with Ollama models\n",
    "- `requests`: For API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db681a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220adcd0",
   "metadata": {},
   "source": [
    "# Load Environment Variables\n",
    "Environment variables are used to securely store sensitive information. We use `load_dotenv()` to load these variables from a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ec72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "ollama_model = os.getenv(\"OLLAMA_MODEL\", \"llama2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4718ae",
   "metadata": {},
   "source": [
    "# Create a Google Search Prompt\n",
    "A prompt is a question or instruction you send to the language model. Here, we'll ask the model to simulate a Google Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Search Google for the latest news about AI.\"\n",
    "response = ollama.chat(model=ollama_model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "print(\"Response:\", response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2663518",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Try changing the prompt to interact with other APIs or services!*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
