{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d7df0d",
   "metadata": {},
   "source": [
    "# LangChain + Ollama: Weather to Slack Agent Lab\n",
    "\n",
    "This notebook demonstrates how to use a locally running Ollama model to generate weather updates and send them to Slack. You'll learn how to set up the environment, send prompts, and interpret the model's output for Slack integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce96cc7d",
   "metadata": {},
   "source": [
    "# Install Required Packages\n",
    "To use LangChain with Ollama, you need to install the following Python packages:\n",
    "- `ollama`: Python client for locally running Ollama models\n",
    "- `langchain_community`: Community-contributed LangChain tools\n",
    "- `python-dotenv`: For loading environment variables from a `.env` file\n",
    "- `requests`: For making API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b45dd8",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "We need to import the following libraries:\n",
    "- `os`: For accessing environment variables\n",
    "- `load_dotenv` from `dotenv`: To load variables from a `.env` file\n",
    "- `ollama`: To interact with Ollama models\n",
    "- `requests`: For API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33126724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ollama\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7226ab",
   "metadata": {},
   "source": [
    "# Load Environment Variables\n",
    "Environment variables are used to securely store sensitive information. We use `load_dotenv()` to load these variables from a `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "ollama_model = os.getenv(\"OLLAMA_MODEL\", \"llama2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeb9b89",
   "metadata": {},
   "source": [
    "# Create a Weather to Slack Prompt\n",
    "A prompt is a question or instruction you send to the language model. Here, we'll ask the model to generate a weather update for Slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7df679",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Send today's Bangalore weather update to Slack.\"\n",
    "response = ollama.chat(model=ollama_model, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "print(\"Response:\", response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7f733a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Try changing the prompt to send different updates or messages to Slack!*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
