{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1ac95a",
   "metadata": {},
   "source": [
    "# LangChain RAG Lab: Resume Q&A with Robo1! ðŸ“„ðŸ¤–\n",
    "\n",
    "Welcome to the LangChain RAG (Retrieval-Augmented Generation) Lab! In this notebook, you'll build a chatbot that answers interview questions using your resume. Robo1 is here to helpâ€”he loves finding answers in big piles of documents!\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>\"I can search your resume faster than you can say 'curriculum vitae'!\"</i><br>\n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "Let's get started and see how RAG makes chatbots smarter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c393d81",
   "metadata": {},
   "source": [
    "# What is RAG (Retrieval-Augmented Generation)?\n",
    "RAG combines the power of search (retrieval) with language models (generation). Instead of guessing, your chatbot can look up answers in documentsâ€”like your resume!\n",
    "\n",
    "Robo1 loves RAG because it means less guessing and more knowing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c7201",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup\n",
    "Let's import the necessary libraries and set up our environment for RAG-powered resume Q&A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42cb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331ea21",
   "metadata": {},
   "source": [
    "# Load and Chunk Your Resume\n",
    "Let's load your resume PDF and split it into smaller chunks so Robo1 can search it efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19025a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"my_resume.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Split resume into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d14705",
   "metadata": {},
   "source": [
    "### Create a Vector Store and Retriever\n",
    "We'll turn your resume chunks into searchable vectors so Robo1 can find the best answers fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6105f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c42dc01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in FAISS vectorstore: 11\n",
      "Document IDs: ['91c8ff07-6649-424d-81b4-d35cd433ce59', '6468db77-4c09-48ce-9c0d-337bc7ab8e00', '1e429873-0d8c-46ea-b1ae-d489794a00b2', '4fc6f51f-deb9-4dc0-877a-39e6900565ae', '1747695d-2f73-4284-bc82-7e8b5e742ab2']\n",
      "Sample document content:\n",
      " K e y  S k i l l s\n",
      "A b o u t  m e\n",
      "      + 9 1 - 8 8 0 0 1 7 5 5 4 4\n",
      "        n a v d e e p 2 2 0 1 6 1 @ g m a i l . c o m\n",
      "N a v d e e p  K a u r\n",
      "C o r p o r a t e   T r a i n e r  ( D a t a / C l o u d / M L  E n g i n e e r i n g )\n",
      "P r e m i u m  I n s t r u c t o r  w i t h  1 4 +  y e a r s  o f  i n d u s t r y\n",
      "e x p e r i e n c e  i n  d i f f e r e n t  d o m a i n s  &  m u l t i p l e\n",
      "t e c h n o l o g i e s . S u c c e s s f u l l y  d e s i g n e d  a n d  c o n d u c t e d\n",
      "o v e r  2 5 0 +  h a n d s - o n ,  r e a l - w o r l d  t r a i n i n g  s e s s i o n s  f o r\n",
      "r e p u t e d  M N C s ,  f o c u s i n g  o n  B i g  D a t a ,  C l o u d ,  D e v O p s ,\n",
      "a n d  A I  t e c h n o l o g i e s .\n",
      "T R A I N I N G  E X P E R I E N C E  \n",
      "B i g  D a t a  T e c h n o l o g i e s :  C o m p r e h e n s i v e  t r a i n i n g  o n  A p a c h e\n",
      "S p a r k ,  H a d o o p ,  C o n f l u e n t  K a f k a ,  a n d  A p a c h e  H u d i / I c e b e r g ,\n",
      "FAISS index shape: 11 vectors, 1536 dimensions\n",
      "Sample vector (first 10 values): [-0.029419   -0.00807348  0.02379478 -0.02393434  0.00401581  0.02874912\n",
      " -0.01299293 -0.02802342 -0.01278359 -0.02606959]\n"
     ]
    }
   ],
   "source": [
    "# Display information about the FAISS vector store\n",
    "print(\"Number of documents in FAISS vectorstore:\", len(vectorstore.docstore._dict))\n",
    "print(\"Document IDs:\", list(vectorstore.docstore._dict.keys())[:5])  # Show first 5 IDs\n",
    "\n",
    "# Optionally, show a sample document stored in FAISS\n",
    "sample_id = list(vectorstore.docstore._dict.keys())[0]\n",
    "print(\"Sample document content:\\n\", vectorstore.docstore._dict[sample_id].page_content)\n",
    "\n",
    "# Show vector representation details\n",
    "print(\"FAISS index shape:\", vectorstore.index.ntotal, \"vectors,\", vectorstore.index.d, \"dimensions\")\n",
    "sample_vector = vectorstore.index.reconstruct(0)\n",
    "print(\"Sample vector (first 10 values):\", sample_vector[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d84830",
   "metadata": {},
   "source": [
    "### Build the RAG Chatbot Chain\n",
    "Now we'll connect everything together so Robo1 can answer your interview questions using your resume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f894957",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are answering interview questions based on the following resume context.\n",
    "If the answer is not in the context, say \\\"I don't know based on my resume.\\\"\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer as if you are the candidate:\n",
    "\"\"\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": PromptTemplate.from_template(prompt_template)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a499dc",
   "metadata": {},
   "source": [
    "# Chat with Your Resume!\n",
    "Ask interview questions and see how Robo1 answers using your resume. If he can't find the answer, he'll let you know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf279012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: {'query': 'What are your technical skills?', 'result': '\\nBased on my resume, I have experience with multiple team and deciding on technologies, helping multiple teams to ramp up on various technologies, handling teams to create robust big data pipelines, and ensuring best and secure practices. I have also migrated teams from on-premise to cloud on Kubernetes. My experience as a Big Data Architect/Manager has allowed me to educate teams on GenAI and AI technologies, as well as introduce them to GenAI fundamentals and practical applications with LangChain and Hugging Face. In terms of technical skills, I have experience with Apache Spark/PySpark, Apache Kafka, Apache Airflow, Hadoop Ecosystem, Apache Hudi/Iceberg, Apache Beam, Kubernetes/Dockers, AWS Cloud, Google Cloud, MLOps/MLE, NoSQL databases, Snowflake/DBT, Starburst/Trino, MinIO, GenAI, Databricks, Apache Flink, and programming languages such as Scala, Python, and Java. I am also certified as a Confluent Certified Administrator for Apache Kafka, AWS Solution Architect/Practitioner/Data Analytics, CCA Data Analyst, Cloudera Certified Professional Data Engineer, DataBricks Certified Associate Developer for Apache Spark, AWS Certified Solution Architect, CCA175 Spark & Hadoop'}\n"
     ]
    }
   ],
   "source": [
    "# Ask your interview question here\n",
    "question = \"What are your technical skills?\"\n",
    "answer = qa_chain.invoke({\"query\": question})\n",
    "print(\"Bot:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eed6e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>\"Congratulations! You just built a RAG-powered chatbot. Now I can ace any interviewâ€”unless they ask about my favorite pizza topping!\"</i><br>\n",
    "<i>With RAG, your AI can find answers in documents faster than ever. ðŸ“„ðŸ¤–</i>\n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "*Thanks for completing the LangChain RAG Lab!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
