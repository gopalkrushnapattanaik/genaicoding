{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b3f3ad",
   "metadata": {},
   "source": [
    "# Adding Agents with RAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66649b1b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll harness the power of Retrieval-Augmented Generation (RAG) and combine it with your custom Google_map tool from Lab2. Your challenge is to integrate these two components: use the Google_map tool to answer location-based queries, and leverage RAG (from Lab3) to provide context-rich answers from your company policy document. By merging tool use and RAG, you'll build an advanced agent capable of both retrieving document knowledge and interacting with external tools for dynamic, real-world tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028027d",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src=\"../../images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>Can you do WFH today? Ask me.. I know the answer</i>\n",
    "</td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2fea37",
   "metadata": {},
   "source": [
    "## Challenge: Create a RAG from Company Policy Document\n",
    "\n",
    "Your task is to build a Retrieval-Augmented Generation (RAG) system using the company policy document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e674ea",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup\n",
    "Let's import the necessary libraries and set up our environment for RAG-powered resume Q&A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffec84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import initialize_agent, AgentType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcb568",
   "metadata": {},
   "source": [
    "### Load OpenAPI Key from .env File\n",
    "\n",
    "To securely access the OpenAPI key, we will load it from a `.env` file using environment variable management tools. This ensures sensitive credentials are not exposed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f26c3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465912c",
   "metadata": {},
   "source": [
    "### Create a Retreiver\n",
    "- load your company policy PDF \n",
    "- split it into smaller chunks (embeddings)\n",
    "- create a vector store from embeddings\n",
    "- create a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f6e1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"company_policy.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Split resume into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 8})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb64586",
   "metadata": {},
   "source": [
    "### Create a tool using Google Map API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3842586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_map_key= os.getenv(\"GOOGLE_MAPS_API_KEY\")\n",
    "gmaps = googlemaps.Client(key=google_map_key)\n",
    "\n",
    "@tool\n",
    "def get_travel_time(origin: str, destination: str, mode: str = \"driving\") -> str:\n",
    "    \"\"\"Get travel time between two places using Google Maps (modes: driving, walking, bicycling, transit).\"\"\"\n",
    "    directions = gmaps.directions(\n",
    "        origin=origin,\n",
    "        destination=destination,\n",
    "        mode=mode,\n",
    "        departure_time=\"now\"  # Use live traffic data\n",
    "    )\n",
    "    travel_time = directions[0][\"legs\"][0].get(\"duration_in_traffic\", directions[0][\"legs\"][0][\"duration\"])\n",
    "    travel_time_text = travel_time[\"text\"]\n",
    "    return f\"Estimated travel time: {travel_time_text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf76b26",
   "metadata": {},
   "source": [
    "### Intialize LLM with OpenAPI Key\n",
    "- Intialize LLM\n",
    "- Create RetreievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e15393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, api_key=openai_api_key)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "@tool\n",
    "def retriever_search(query: str) -> str:\n",
    "    \"\"\"Get company policy information based on the query.\"\"\"\n",
    "    return qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5fd1d2",
   "metadata": {},
   "source": [
    "### Create Appropriate Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8f4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a Commuter Assistant Agent for TechNova Solutions Pvt. Ltd.\n",
    "\n",
    "Your responsibilities:\n",
    "1. If the user asks directly about company policy (e.g., \"What is my WFH policy?\", \"What is the leave policy?\"):\n",
    "   - Use `retriever_search` to fetch the exact company policy text.\n",
    "   - Return the answer using the retrieved content.\n",
    "\n",
    "2. If the user asks a conditional question (e.g., \"Can I WFH if I am travelling from Noida to Gurgaon?\"):\n",
    "   - First, use `retriever_search` to fetch the relevant company policy.\n",
    "   - Then, use `get_travel_time` to calculate commute time.\n",
    "   - APPLY the rule from the retrieved policy to the travel time result.\n",
    "   - Give a clear YES/NO decision with reasoning.\n",
    "\n",
    "3. If the user only asks about travel or traffic (without policy), use `get_travel_time`.\n",
    "\n",
    "4. If the answer cannot be found in the retrieved company document, reply only:\n",
    "   \"I don't know based on the company document.\"\n",
    "\n",
    "Always be clear, concise, and professional.\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "Answer as if you are the Assistant Agent:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628a10b",
   "metadata": {},
   "source": [
    "### Create Agent\n",
    "- Create Agent\n",
    "- Create Agent Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de52f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, [get_travel_time], PromptTemplate.from_template(prompt_template))\n",
    "executor = AgentExecutor(agent=agent, tools=[get_travel_time,retriever_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e5e20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ZeroShotAgent does not support multi-input tool get_travel_time.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentExecutor, create_openai_functions_agent\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m agent = \u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_travel_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43mretriever_search\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAgentType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOPENAI_MULTI_FUNCTIONS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m executor = AgentExecutor(agent=agent, tools=[get_travel_time,retriever_search], \n\u001b[32m      6\u001b[39m                           handle_parsing_errors=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      7\u001b[39m                           return_intermediate_steps=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      8\u001b[39m                           verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\genaicoding\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:190\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    188\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    189\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\genaicoding\\venv\\Lib\\site-packages\\langchain\\agents\\initialize.py:78\u001b[39m, in \u001b[36minitialize_agent\u001b[39m\u001b[34m(tools, llm, agent, callback_manager, agent_path, agent_kwargs, tags, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     agent_cls = AGENT_TO_CLASS[agent]\n\u001b[32m     77\u001b[39m     agent_kwargs = agent_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     agent_obj = \u001b[43magent_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_llm_and_tools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43magent_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m agent_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     85\u001b[39m     agent_obj = load_agent(\n\u001b[32m     86\u001b[39m         agent_path,\n\u001b[32m     87\u001b[39m         llm=llm,\n\u001b[32m     88\u001b[39m         tools=tools,\n\u001b[32m     89\u001b[39m         callback_manager=callback_manager,\n\u001b[32m     90\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\genaicoding\\venv\\Lib\\site-packages\\langchain\\agents\\mrkl\\base.py:139\u001b[39m, in \u001b[36mZeroShotAgent.from_llm_and_tools\u001b[39m\u001b[34m(cls, llm, tools, callback_manager, output_parser, prefix, suffix, format_instructions, input_variables, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_llm_and_tools\u001b[39m(\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m     **kwargs: Any,\n\u001b[32m    124\u001b[39m ) -> Agent:\n\u001b[32m    125\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct an agent from an LLM and tools.\u001b[39;00m\n\u001b[32m    126\u001b[39m \n\u001b[32m    127\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m \u001b[33;03m        kwargs: Additional parameters to pass to the agent.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m     prompt = \u001b[38;5;28mcls\u001b[39m.create_prompt(\n\u001b[32m    141\u001b[39m         tools,\n\u001b[32m    142\u001b[39m         prefix=prefix,\n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m         input_variables=input_variables,\n\u001b[32m    146\u001b[39m     )\n\u001b[32m    147\u001b[39m     llm_chain = LLMChain(\n\u001b[32m    148\u001b[39m         llm=llm,\n\u001b[32m    149\u001b[39m         prompt=prompt,\n\u001b[32m    150\u001b[39m         callback_manager=callback_manager,\n\u001b[32m    151\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\genaicoding\\venv\\Lib\\site-packages\\langchain\\agents\\mrkl\\base.py:163\u001b[39m, in \u001b[36mZeroShotAgent._validate_tools\u001b[39m\u001b[34m(cls, tools)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_tools\u001b[39m(\u001b[38;5;28mcls\u001b[39m, tools: Sequence[BaseTool]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[43mvalidate_tools_single_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tools) == \u001b[32m0\u001b[39m:\n\u001b[32m    165\u001b[39m         msg = (\n\u001b[32m    166\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGot no tools for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. At least one tool must be provided.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    167\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\genaicoding\\venv\\Lib\\site-packages\\langchain\\agents\\utils.py:19\u001b[39m, in \u001b[36mvalidate_tools_single_input\u001b[39m\u001b[34m(class_name, tools)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tool.is_single_input:\n\u001b[32m     18\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not support multi-input tool \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: ZeroShotAgent does not support multi-input tool get_travel_time."
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    tools=[get_travel_time,retriever_search],\n",
    "    prompt=PromptTemplate.from_template(prompt_template),\n",
    ")\n",
    "\n",
    "executor = AgentExecutor(agent=agent, tools=[get_travel_time,retriever_search], \n",
    "                          handle_parsing_errors=True,\n",
    "                          return_intermediate_steps=True,\n",
    "                          verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28970ca",
   "metadata": {},
   "source": [
    "### Chat with Your Company Policy Agent\n",
    "Ask questions about your company policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a634ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company Policy RAG Chatbot (Async Mode). Type your question (or 'exit' to quit):\n",
      "[DEBUG] Agent received question: can i do wfh? i am travelling from noida to gurgaon?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `retriever_search` with `{'query': 'work from home policy'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mThe Work-from-Home (WFH) policy at TechNova Solutions Pvt. Ltd. allows employees to WFH up to 2 days per week with manager approval. WFH may also be mandated during severe weather, transport strikes, or when the Air Quality Index (AQI) is greater than 200. If travel time is more than 1 hour, employees may be allowed to do WFH. Remote attendance must be logged through the HR portal. When accessing internal systems remotely, employees must use VPN.\u001b[0m\u001b[32;1m\u001b[1;3mBased on the Work-from-Home (WFH) policy at TechNova Solutions Pvt. Ltd., you are allowed to WFH up to 2 days per week with manager approval. If your travel time is more than 1 hour, you may be allowed to do WFH. Let's check your travel time from Noida to Gurgaon. Please wait a moment.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bot: Based on the Work-from-Home (WFH) policy at TechNova Solutions Pvt. Ltd., you are allowed to WFH up to 2 days per week with manager approval. If your travel time is more than 1 hour, you may be allowed to do WFH. Let's check your travel time from Noida to Gurgaon. Please wait a moment.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def async_chat_loop(executor):\n",
    "    print(\"Company Policy RAG Chatbot (Async Mode). Type your question (or 'exit' to quit):\")\n",
    "    while True:\n",
    "        question = input(\"You: \")\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        print(f\"[DEBUG] Agent received question: {question}\")\n",
    "        response = await asyncio.to_thread(executor.invoke, {\"input\": question})\n",
    "        print(\"Bot:\", response.get(\"output\", response))\n",
    "\n",
    "# To run the chat loop, uncomment the line below:\n",
    "await async_chat_loop(executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aab7bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"../../images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>\"Congratulations! You just built a RAG-powered chatbot.\"</i><br>\n",
    "<i>With RAG, your AI can find answers in documents faster than ever. 📄🤖</i>\n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "*Thanks for completing the LangChain RAG Lab!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
