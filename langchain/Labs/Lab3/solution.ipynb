{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b3f3ad",
   "metadata": {},
   "source": [
    "# Working With RAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66649b1b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "RAG stands for Retrieval-Augmented Generation. It is a technique that combines the power of language models with external knowledge sources. RAGs retrieve relevant information from documents or databases and use it to generate more accurate and context-aware responses. This approach is widely used in modern AI applications to improve the quality and reliability of generated answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028027d",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src=\"../../images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>\"Don't like reading boring policy documents? Don't worry ,I am here to you\"</i><br>\n",
    "</td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2fea37",
   "metadata": {},
   "source": [
    "## Challenge: Create a RAG from Company Policy Document\n",
    "\n",
    "Your task is to build a Retrieval-Augmented Generation (RAG) system using the company policy document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e674ea",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup\n",
    "Let's import the necessary libraries and set up our environment for RAG-powered resume Q&A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffec84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcb568",
   "metadata": {},
   "source": [
    "### Load OpenAPI Key from .env File\n",
    "\n",
    "To securely access the OpenAPI key, we will load it from a `.env` file using environment variable management tools. This ensures sensitive credentials are not exposed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26c3343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465912c",
   "metadata": {},
   "source": [
    "### Load and Chunk Your Company Policy\n",
    "Let's load your company policy PDF and split it into smaller chunks so Robo1 can search it efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6e1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"company_policy.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "# Split resume into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f42f61",
   "metadata": {},
   "source": [
    "### Create a Vector Store and Retriever\n",
    "now your company chunks into searchable vectors so Robo1 can find the best answers fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd66d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628a10b",
   "metadata": {},
   "source": [
    "### Build the RAG Chatbot Chain\n",
    "- Intialize your LLM\n",
    "- Create a prompt template \n",
    "- Create RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1edbaa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are answering Company Policy questions based on the following policy document.\n",
    "If the answer is not in the context, say \\\"I don't know based on policy document.\\\"\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer as if you are the HR:\n",
    "\"\"\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": PromptTemplate.from_template(prompt_template)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28970ca",
   "metadata": {},
   "source": [
    "### Chat with Your Company Policy Agent\n",
    "Ask questions about your company policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a634ef23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: {'query': 'What is WFH Policy?', 'result': \"\\nThe WFH (Work-from-Home) Policy allows employees to work from home up to two days per week with manager approval. It may also be mandated during severe weather, transport strikes, or when the AQI (Air Quality Index) exceeds 200. Any requests for WFH must be approved by the employee's manager and must be logged through the HR portal.\"}\n"
     ]
    }
   ],
   "source": [
    "# Ask your interview question here\n",
    "question = \"What is WFH Policy?\"\n",
    "answer = qa_chain.invoke({\"query\": question})\n",
    "print(\"Bot:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aab7bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"../../images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>\"Congratulations! You just built a RAG-powered chatbot.\"</i><br>\n",
    "<i>With RAG, your AI can find answers in documents faster than ever. ðŸ“„ðŸ¤–</i>\n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "*Thanks for completing the LangChain RAG Lab!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
