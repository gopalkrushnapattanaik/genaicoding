{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b3f3ad",
   "metadata": {},
   "source": [
    "# Working With RAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66649b1b",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "RAG stands for Retrieval-Augmented Generation. It is a technique that combines the power of language models with external knowledge sources. RAGs retrieve relevant information from documents or databases and use it to generate more accurate and context-aware responses. This approach is widely used in modern AI applications to improve the quality and reliability of generated answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028027d",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><img src=\"../../images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>\"Don't like reading boring policy documents? Don't worry ,I am here to you\"</i><br>\n",
    "</td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2fea37",
   "metadata": {},
   "source": [
    "## Challenge: Create a RAG from Company Policy Document\n",
    "\n",
    "Your task is to build a Retrieval-Augmented Generation (RAG) system using the company policy document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e674ea",
   "metadata": {},
   "source": [
    "# Import Libraries and Setup\n",
    "Let's import the necessary libraries and set up our environment for RAG-powered resume Q&A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec84a2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcb568",
   "metadata": {},
   "source": [
    "### Load OpenAPI Key from .env File\n",
    "\n",
    "To securely access the OpenAPI key, we will load it from a `.env` file using environment variable management tools. This ensures sensitive credentials are not exposed in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c3343",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get OpenAI API key from environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465912c",
   "metadata": {},
   "source": [
    "### Load and Chunk Your Company Policy\n",
    "Let's load your company policy PDF and split it into smaller chunks so Robo1 can search it efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e1dcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68f42f61",
   "metadata": {},
   "source": [
    "### Create a Vector Store and Retriever\n",
    "now your company chunks into searchable vectors so Robo1 can find the best answers fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd66d33a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7628a10b",
   "metadata": {},
   "source": [
    "### Build the RAG Chatbot Chain\n",
    "- Intialize your LLM\n",
    "- Create a prompt template \n",
    "- Create RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbaa32",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e28970ca",
   "metadata": {},
   "source": [
    "### Chat with Your Company Policy Agent\n",
    "Ask questions about your company policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634ef23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34aab7bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<table><tr>\n",
    "<td><img src=\"../../images/robo1.png\" alt=\"Robo1 - RAG Expert\" width=\"120\" /></td>\n",
    "<td style=\"vertical-align:top; padding-left:20px;\">\n",
    "<b>Robo1 says:</b><br>\n",
    "<i>\"Congratulations! You just built a RAG-powered chatbot.\"</i><br>\n",
    "<i>With RAG, your AI can find answers in documents faster than ever. ðŸ“„ðŸ¤–</i>\n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "*Thanks for completing the LangChain RAG Lab!*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
