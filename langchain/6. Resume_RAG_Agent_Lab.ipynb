{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfe2c004",
   "metadata": {},
   "source": [
    "# Resume RAG Agent with SMS Notification\n",
    "Welcome to the Resume RAG Agent Lab!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cef3c2",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you'll build an autonomous Resume RAG (Retrieval-Augmented Generation) chatbot agent. The agent answers interview questions using information from a resume PDF. If the answer isn't found, it sends an SMS notification to the user. You'll learn how to:\n",
    "- Load and process a resume PDF\n",
    "- Use semantic search with embeddings\n",
    "- Integrate Twilio for SMS notifications\n",
    "- Run an async chat loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23ee98",
   "metadata": {},
   "source": [
    "---\n",
    "<div style=\"border: 2px solid #ccc; border-radius: 12px; padding: 16px; background: #111; display: flex; align-items: center; gap: 24px;\">\n",
    "    <img src=\"images/robo7.png\" alt=\"Robo7\" style=\"width:120px;\"/>\n",
    "    <div>\n",
    "        <h3 style=\"color:#fff;\">Meet Robo7!</h3>\n",
    "        <p style=\"color:#eee;\">If the Resume RAG Agent can't find an answer in your resume, Robo7 will send you an SMS to let you know! ðŸ¤–ðŸ“±</p>\n",
    "        <em style=\"color:#bbb;\">\"When in doubt, Robo7 texts it out!\"</em>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf768f",
   "metadata": {},
   "source": [
    "## Resume RAG Agent Implementation\n",
    "\n",
    "This section implements the Resume RAG Agent using LangChain, OpenAI, FAISS, and Twilio. The agent answers interview questions using your resume PDF. If the answer is not found, it sends an SMS notification using Twilio.\n",
    "\n",
    "**Workflow:**\n",
    "- Load resume PDF and split into chunks\n",
    "- Embed and index chunks for semantic search\n",
    "- Define tools for resume search and SMS notification\n",
    "- Create a conversational agent with a custom prompt\n",
    "- Run an interactive chat loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94279932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twilio.rest import Client\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Twilio credentials\n",
    "twilio_sid = os.getenv(\"TWILIO_ACCOUNT_SID\")\n",
    "twilio_token = os.getenv(\"TWILIO_AUTH_TOKEN\")\n",
    "twilio_from = os.getenv(\"TWILIO_FROM_NUMBER\")\n",
    "twilio_to = os.getenv(\"TWILIO_TO_NUMBER\")\n",
    "\n",
    "# Create twilio client\n",
    "twilio_client = Client(twilio_sid, twilio_token)\n",
    "\n",
    "def send_sms_tool(message: str) -> str:\n",
    "    print(f\"[DEBUG] Sending SMS: {message}\")\n",
    "    twilio_client.messages.create(\n",
    "        body=message,\n",
    "        from_=twilio_from,\n",
    "        to=twilio_to\n",
    "    )\n",
    "    return \"SMS sent to your phone.\"\n",
    "\n",
    "twilio_tool = Tool(\n",
    "    name=\"twilio_tool\",\n",
    "    func=send_sms_tool,\n",
    "    description=\"If you ever answer 'I don't know based on my resume.', immediately use this tool to notify the user by SMS. When you use this tool, send the original interview question that was asked, not the fallback answer.\"\n",
    ")\n",
    "\n",
    "def resume_search_tool(query: str) -> str:\n",
    "    result = qa_chain.invoke({\"query\": query})\n",
    "    if isinstance(result, dict):\n",
    "        answer = str(result)\n",
    "    print(f\"[DEBUG] Resume search result: {answer}\")\n",
    "    if answer.strip() == \"\" or \"I don't know\" in answer:\n",
    "        return \"I don't know based on my resume.\"\n",
    "    return answer\n",
    "\n",
    "resume_tool = Tool(\n",
    "    name=\"resume_search\",\n",
    "    func=resume_search_tool,\n",
    "    description=\"Use this tool to search the resume and answer interview questions based on its content. If the answer is not found, return 'I don't know based on my resume.' as a string. If you ever answer 'I don't know based on my resume.', you must immediately use the twilio_tool to notify the user by SMS.\"\n",
    ")\n",
    "\n",
    "pdf_path = \"my_resume.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0, api_key=openai_api_key)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are answering interview questions based on the resume.\n",
    "If the answer is not in the resume, say \"I don't know based on my resume.\" If you ever answer 'I don't know based on my resume.', you must immediately use the twilio_tool to notify the user by SMS. When you use the twilio_tool, send the original interview question that was asked, not the fallback answer.\n",
    "Question: {input}\n",
    "{agent_scratchpad}\n",
    "Answer as if you are the candidate:\n",
    "\"\"\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "agent = create_tool_calling_agent(llm, [resume_tool, twilio_tool], PromptTemplate.from_template(prompt_template))\n",
    "executor = AgentExecutor(agent=agent, tools=[resume_tool, twilio_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5896b0",
   "metadata": {},
   "source": [
    "## Async Chat Loop\n",
    "\n",
    "The following cell runs the Resume RAG Agent in async mode. Type your interview questions and get responses. If the answer is not found in your resume, you'll receive an SMS notification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9adc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume RAG Chatbot (Async Mode). Type your interview question (or 'exit' to quit):\n",
      "[DEBUG] Agent received question: what are your skills?\n",
      "[DEBUG] Resume search result: {'query': 'skills', 'result': 'The individual has skills in:\\n\\n1. Creating and managing secure practices for pipelines.\\n2. Migrating teams from on-premise to cloud on Kubernetes.\\n3. Big Data Architecture and Management.\\n4. AWS (Amazon Web Services).\\n5. Apache Spark.\\n6. Kubernetes.\\n7. Airflow.\\n8. Java, Spring, Web Server, Hibernate.\\n9. Understanding requirements and advising on technologies.'}\n",
      "Bot: Based on my resume, my skills include:\n",
      "\n",
      "1. Creating and managing secure practices for pipelines.\n",
      "2. Migrating teams from on-premise to cloud on Kubernetes.\n",
      "3. Big Data Architecture and Management.\n",
      "4. AWS (Amazon Web Services).\n",
      "5. Apache Spark.\n",
      "6. Kubernetes.\n",
      "7. Airflow.\n",
      "8. Java, Spring, Web Server, Hibernate.\n",
      "9. Understanding requirements and advising on technologies.\n",
      "[DEBUG] Agent received question: Do you have a patent?\n",
      "[DEBUG] Resume search result: {'query': 'patent', 'result': \"I'm sorry, but the information provided does not mention anything about a patent.\"}\n",
      "Bot: I don't know based on my resume.\n",
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_2', 'function': {'arguments': '\\n{\\n  \"__arg1\": \"Do you have a patent?\"\\n}', 'name': 'twilio_tool'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4-0613', 'service_tier': 'default'}, id='run--19ab11e0-a8c6-4b5d-b63f-315252d1025d', tool_calls=[{'name': 'twilio_tool', 'args': {'__arg1': 'Do you have a patent?'}, 'id': 'call_2', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'twilio_tool', 'args': '\\n{\\n  \"__arg1\": \"Do you have a patent?\"\\n}', 'id': 'call_2', 'index': 0, 'type': 'tool_call_chunk'}])]\n",
      "I have sent a notification to the user about this question.\n",
      "[DEBUG] Agent received question: are you married?\n",
      "[DEBUG] Resume search result: {'query': 'are you married?', 'result': \"I'm an artificial intelligence and do not have personal relationships or marital status.\"}\n",
      "Bot: I'm an artificial intelligence and do not have personal relationships or marital status.\n",
      "[DEBUG] Agent received question: do you have patent?\n",
      "[DEBUG] Resume search result: {'query': 'patent', 'result': \"I'm sorry, but the information provided does not mention anything about a patent.\"}\n",
      "Bot: I don't know based on my resume.\n",
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_2FVIGowIpGHuae', 'function': {'arguments': '\\n{\\n  \"__arg1\": \"do you have patent?\"\\n}', 'name': 'twilio_tool'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4-0613', 'service_tier': 'default'}, id='run--4b387de8-c831-4ba2-9ae6-307b54436f69', tool_calls=[{'name': 'twilio_tool', 'args': {'__arg1': 'do you have patent?'}, 'id': 'call_2FVIGowIpGHuae', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'twilio_tool', 'args': '\\n{\\n  \"__arg1\": \"do you have patent?\"\\n}', 'id': 'call_2FVIGowIpGHuae', 'index': 0, 'type': 'tool_call_chunk'}])]\n",
      "I don't know based on my resume.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def async_chat_loop(executor):\n",
    "    print(\"Resume RAG Chatbot (Async Mode). Type your interview question (or 'exit' to quit):\")\n",
    "    while True:\n",
    "        question = input(\"You: \")\n",
    "        if question.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        print(f\"[DEBUG] Agent received question: {question}\")\n",
    "        response = await asyncio.to_thread(executor.invoke, {\"input\": question})\n",
    "        print(\"Bot:\", response.get(\"output\", response))\n",
    "\n",
    "# To run the chat loop, uncomment the line below:\n",
    "await async_chat_loop(executor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
